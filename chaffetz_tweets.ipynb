{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Jason Chaffetz' Legacy on Twitter\n",
    "\n",
    "By [Sean McMinn](http://www.github.com/shmcminn)\n",
    "\n",
    "As Utah Republican Rep. Jason Chaffetz prepared to retire on June 30, 2017, Roll Call used this script to parse his most recent tweets, up to the Twitter API cap, then analyze them. Roll Call published the [graphic story](http://www.rollcall.com/news/politics/measuring-chaffetzs-legacy-twitter) using this analaysis on June 29. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "\n",
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "import csv\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "#Twitter API credentials\n",
    "consumer_key = \"INSERT_HERE\"\n",
    "consumer_secret = \"INSERT_HERE\"\n",
    "access_key = \"INSERT_HERE\"\n",
    "access_secret = \"INSERT_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function from https://gist.github.com/yanofsky/5436496\n",
    "\n",
    "def get_all_tweets(screen_name):\n",
    "\t#Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "\t\n",
    "\t#authorize twitter, initialize tweepy\n",
    "\tauth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "\tauth.set_access_token(access_key, access_secret)\n",
    "\tapi = tweepy.API(auth)\n",
    "\t\n",
    "\t#initialize a list to hold all the tweepy Tweets\n",
    "\talltweets = []\t\n",
    "\t\n",
    "\t#make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "\tnew_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "\t\n",
    "\t#save most recent tweets\n",
    "\talltweets.extend(new_tweets)\n",
    "\t\n",
    "\t#save the id of the oldest tweet less one\n",
    "\toldest = alltweets[-1].id - 1\n",
    "\t\n",
    "\t#keep grabbing tweets until there are no tweets left to grab\n",
    "\twhile len(new_tweets) > 0:\n",
    "\t\tprint(\"getting tweets before %s\" % (oldest))\n",
    "\t\t\n",
    "\t\t#all subsiquent requests use the max_id param to prevent duplicates\n",
    "\t\tnew_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "\t\t\n",
    "\t\t#save most recent tweets\n",
    "\t\talltweets.extend(new_tweets)\n",
    "\t\t\n",
    "\t\t#update the id of the oldest tweet less one\n",
    "\t\toldest = alltweets[-1].id - 1\n",
    "\t\tprint(\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "\t\n",
    "\t#transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "\touttweets = [[tweet.id_str, tweet.created_at, tweet.text, tweet.retweet_count, tweet.favorite_count] for tweet in alltweets]\n",
    "\t\n",
    "\t#write the csv\t\n",
    "\twith open('jasoninthehouse_tweets.csv', 'w') as f:\n",
    "\t\twriter = csv.writer(f)\n",
    "\t\twriter.writerow([\"id\",\"created_at\",\"text\", \"RT\", \"fav\"])\n",
    "\t\twriter.writerows(outtweets)\n",
    "\t\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get  recent tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 836422433443807231\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 804657644606816260\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 769394871601926143\n",
      "...799 tweets downloaded so far\n",
      "getting tweets before 740978125165756415\n",
      "...999 tweets downloaded so far\n",
      "getting tweets before 715303205580750847\n",
      "...1199 tweets downloaded so far\n",
      "getting tweets before 691767066131566591\n",
      "...1399 tweets downloaded so far\n",
      "getting tweets before 670034126716559360\n",
      "...1599 tweets downloaded so far\n",
      "getting tweets before 643578898274385920\n",
      "...1798 tweets downloaded so far\n",
      "getting tweets before 620452746961879039\n",
      "...1998 tweets downloaded so far\n",
      "getting tweets before 596076664104189953\n",
      "...2198 tweets downloaded so far\n",
      "getting tweets before 570626673584021503\n",
      "...2398 tweets downloaded so far\n",
      "getting tweets before 548644361232453631\n",
      "...2598 tweets downloaded so far\n",
      "getting tweets before 516262623063457792\n",
      "...2798 tweets downloaded so far\n",
      "getting tweets before 489611165535059967\n",
      "...2998 tweets downloaded so far\n",
      "getting tweets before 469315427923800064\n",
      "...3198 tweets downloaded so far\n",
      "getting tweets before 427481525106376703\n",
      "...3214 tweets downloaded so far\n",
      "getting tweets before 425470374638145535\n",
      "...3214 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\t#pass in the username of the account you want to download\n",
    "\tget_all_tweets(\"jasoninthehouse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read local CSV of tweets downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# open csv file as list of dicts\n",
    "\n",
    "with open('jasoninthehouse_tweets.csv') as f:\n",
    "    all_tweets = [{k: v for k, v in row.items()}\n",
    "        for row in csv.DictReader(f, skipinitialspace=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse and clean data\n",
    "\n",
    "note: for \"weekday\" key, 1 = Mon and 7 = Sun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make changes to tweet data\n",
    "\n",
    "for twt in all_tweets:\n",
    "    time_minus_four = (datetime.datetime.strptime(twt[\"created_at\"], \"%Y-%m-%d %H:%M:%S\")- datetime.timedelta(hours=4))\n",
    "    twt[\"new_date\"] = str(time_minus_four.date())\n",
    "    twt[\"new_time\"] = str(time_minus_four.time())\n",
    "    twt[\"hour\"] = twt[\"new_time\"][0:2]\n",
    "    twt[\"weekday\"] = time_minus_four.weekday()\n",
    "    if twt[\"weekday\"] is 7:\n",
    "        twt[\"weekday\"] = 0\n",
    "    twt[\"weekday\"] = twt[\"weekday\"] + 1\n",
    "    twt[\"text\"] = twt[\"text\"].replace(\"b'\",\"\")\n",
    "    twt[\"text\"] = twt[\"text\"].replace('b\"',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write csv from new tweet data\n",
    "\n",
    "out_file_name = \"jasoninthehouse_tweets.csv\"\n",
    "\n",
    "with open(out_file_name, \"w\") as csvfile:\t\n",
    "\tfieldnames = all_tweets[0].keys()\n",
    "\twriter = csv.DictWriter(csvfile, fieldnames = fieldnames)\n",
    "\twriter.writeheader()\n",
    "\tfor el in all_tweets:\n",
    "\t\twriter.writerow(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find most popular tweets\n",
    "\n",
    "## Most retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'RT': '41327',\n",
       "  'created_at': '2017-06-15 02:00:34',\n",
       "  'fav': '0',\n",
       "  'hour': '22',\n",
       "  'id': '875171141605785600',\n",
       "  'new_date': '2017-06-14',\n",
       "  'new_time': '22:00:34',\n",
       "  'text': 'RT @realDonaldTrump: Just left hospital. Rep. Steve Scalise, one of the truly great people, is in very tough shape - but he is a real fight…',\n",
       "  'weekday': 3},\n",
       " {'RT': '21829',\n",
       "  'created_at': '2016-10-28 16:57:17',\n",
       "  'fav': '29685',\n",
       "  'hour': '12',\n",
       "  'id': '792047597040971776',\n",
       "  'new_date': '2016-10-28',\n",
       "  'new_time': '12:57:17',\n",
       "  'text': 'FBI Dir just informed me, \"The FBI has learned of the existence of emails that appear to be pertinent to the investigation.\" Case reopened',\n",
       "  'weekday': 5},\n",
       " {'RT': '11543',\n",
       "  'created_at': '2016-11-06 20:15:36',\n",
       "  'fav': '10758',\n",
       "  'hour': '16',\n",
       "  'id': '795358997083586560',\n",
       "  'new_date': '2016-11-06',\n",
       "  'new_time': '16:15:36',\n",
       "  'text': 'FBI Dir just informed us \"Based on our review, we have not changed our conclusions that we expressed in July with respect to Sec Clinton\"',\n",
       "  'weekday': 7},\n",
       " {'RT': '9718',\n",
       "  'created_at': '2017-05-07 03:36:12',\n",
       "  'fav': '0',\n",
       "  'hour': '23',\n",
       "  'id': '861062081855889409',\n",
       "  'new_date': '2017-05-06',\n",
       "  'new_time': '23:36:12',\n",
       "  'text': 'RT @beINSPORTSUSA: Hay Liga!\\n\\n#Messi racks up his 500th career goal. Oh, and it just so happens to settle the best #ElClasico in a long tim…',\n",
       "  'weekday': 6},\n",
       " {'RT': '7706',\n",
       "  'created_at': '2014-09-08 18:23:23',\n",
       "  'fav': '0',\n",
       "  'hour': '14',\n",
       "  'id': '509044341416140801',\n",
       "  'new_date': '2014-09-08',\n",
       "  'new_time': '14:23:23',\n",
       "  'text': 'RT @AdamSchefter: Big news from @mortreport: Ray Rice released. Finished with Baltimore.',\n",
       "  'weekday': 1},\n",
       " {'RT': '7004',\n",
       "  'created_at': '2015-01-11 23:48:25',\n",
       "  'fav': '0',\n",
       "  'hour': '19',\n",
       "  'id': '554424622678949888',\n",
       "  'new_date': '2015-01-11',\n",
       "  'new_time': '19:48:25',\n",
       "  'text': 'RT @PRyan: .@GovChristie, do you need a hug now? #GoPackGo #WinninginWisco http://t.co/32zPv6krRy',\n",
       "  'weekday': 7},\n",
       " {'RT': '6870',\n",
       "  'created_at': '2014-04-11 03:49:15',\n",
       "  'fav': '0',\n",
       "  'hour': '23',\n",
       "  'id': '454466177905860608',\n",
       "  'new_date': '2014-04-10',\n",
       "  'new_time': '23:49:15',\n",
       "  'text': \"RT @StephenAtHome: Let's see...what to tweet about, what to tweet about? I got nothing. What's new with you?\",\n",
       "  'weekday': 4},\n",
       " {'RT': '6162',\n",
       "  'created_at': '2017-05-16 22:58:45',\n",
       "  'fav': '14279',\n",
       "  'hour': '18',\n",
       "  'id': '864616135466950656',\n",
       "  'new_date': '2017-05-16',\n",
       "  'new_time': '18:58:45',\n",
       "  'text': '.@GOPoversight is going to get the Comey memo, if it exists. I need to see it sooner rather than later. I have my subpoena pen ready.',\n",
       "  'weekday': 2},\n",
       " {'RT': '5903',\n",
       "  'created_at': '2016-10-27 01:05:55',\n",
       "  'fav': '10106',\n",
       "  'hour': '21',\n",
       "  'id': '791445788656226304',\n",
       "  'new_date': '2016-10-26',\n",
       "  'new_time': '21:05:55',\n",
       "  'text': 'I will not defend or endorse @realDonaldTrump, but I am voting for him.  HRC is that bad.  HRC is bad for the USA.',\n",
       "  'weekday': 3},\n",
       " {'RT': '5575',\n",
       "  'created_at': '2017-04-16 14:19:27',\n",
       "  'fav': '0',\n",
       "  'hour': '10',\n",
       "  'id': '853613816550047744',\n",
       "  'new_date': '2017-04-16',\n",
       "  'new_time': '10:19:27',\n",
       "  'text': 'RT @VP: Like millions of Americans, my family will commemorate the Resurrection of Jesus Christ, when the mourning of Good Friday gave way…',\n",
       "  'weekday': 7}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top 10 RT'd tweets\n",
    "# be careful on analyzing - some of these are others' tweets Chaffetz RT'd. Could use function to remove tweets that start with \"RT\"\n",
    "\n",
    "most_rts =  sorted(all_tweets, key=lambda k: int(k['RT']), reverse=True)[0:10]\n",
    "\n",
    "most_rts[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets with most likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'RT': '21829',\n",
       "  'created_at': '2016-10-28 16:57:17',\n",
       "  'fav': '29685',\n",
       "  'hour': '12',\n",
       "  'id': '792047597040971776',\n",
       "  'new_date': '2016-10-28',\n",
       "  'new_time': '12:57:17',\n",
       "  'text': 'FBI Dir just informed me, \"The FBI has learned of the existence of emails that appear to be pertinent to the investigation.\" Case reopened',\n",
       "  'weekday': 5},\n",
       " {'RT': '6162',\n",
       "  'created_at': '2017-05-16 22:58:45',\n",
       "  'fav': '14279',\n",
       "  'hour': '18',\n",
       "  'id': '864616135466950656',\n",
       "  'new_date': '2017-05-16',\n",
       "  'new_time': '18:58:45',\n",
       "  'text': '.@GOPoversight is going to get the Comey memo, if it exists. I need to see it sooner rather than later. I have my subpoena pen ready.',\n",
       "  'weekday': 2},\n",
       " {'RT': '11543',\n",
       "  'created_at': '2016-11-06 20:15:36',\n",
       "  'fav': '10758',\n",
       "  'hour': '16',\n",
       "  'id': '795358997083586560',\n",
       "  'new_date': '2016-11-06',\n",
       "  'new_time': '16:15:36',\n",
       "  'text': 'FBI Dir just informed us \"Based on our review, we have not changed our conclusions that we expressed in July with respect to Sec Clinton\"',\n",
       "  'weekday': 7},\n",
       " {'RT': '5903',\n",
       "  'created_at': '2016-10-27 01:05:55',\n",
       "  'fav': '10106',\n",
       "  'hour': '21',\n",
       "  'id': '791445788656226304',\n",
       "  'new_date': '2016-10-26',\n",
       "  'new_time': '21:05:55',\n",
       "  'text': 'I will not defend or endorse @realDonaldTrump, but I am voting for him.  HRC is that bad.  HRC is bad for the USA.',\n",
       "  'weekday': 3},\n",
       " {'RT': '4093',\n",
       "  'created_at': '2017-03-02 13:14:39',\n",
       "  'fav': '9214',\n",
       "  'hour': '09',\n",
       "  'id': '837290054385033218',\n",
       "  'new_date': '2017-03-02',\n",
       "  'new_time': '09:14:39',\n",
       "  'text': 'AG Sessions should clarify his testimony and recuse himself',\n",
       "  'weekday': 4},\n",
       " {'RT': '1851',\n",
       "  'created_at': '2017-02-02 05:07:01',\n",
       "  'fav': '6845',\n",
       "  'hour': '01',\n",
       "  'id': '827020474433544192',\n",
       "  'new_date': '2017-02-02',\n",
       "  'new_time': '01:07:01',\n",
       "  'text': \"I am withdrawing HR 621. I'm a proud gun owner, hunter and love our public lands. The bill would… https://t.co/FLhLaiAzkw\",\n",
       "  'weekday': 4},\n",
       " {'RT': '3930',\n",
       "  'created_at': '2016-09-27 16:24:10',\n",
       "  'fav': '5939',\n",
       "  'hour': '12',\n",
       "  'id': '780805240887111682',\n",
       "  'new_date': '2016-09-27',\n",
       "  'new_time': '12:24:10',\n",
       "  'text': 'Today I filed a privileged report to hold Bryan Pagliano in contempt of Congress #subpoenasarenotoptional https://t.co/WkJZWu8oOq',\n",
       "  'weekday': 2},\n",
       " {'RT': '3867',\n",
       "  'created_at': '2017-05-22 21:39:09',\n",
       "  'fav': '5473',\n",
       "  'hour': '17',\n",
       "  'id': '866770432434741248',\n",
       "  'new_date': '2017-05-22',\n",
       "  'new_time': '17:39:09',\n",
       "  'text': 'Spoke with Comey. He wants to speak with Special Counsel prior to public testimony. Hearing Wed postponed. @GOPoversight',\n",
       "  'weekday': 1},\n",
       " {'RT': '2142',\n",
       "  'created_at': '2017-02-09 22:23:31',\n",
       "  'fav': '4858',\n",
       "  'hour': '18',\n",
       "  'id': '829818033224900608',\n",
       "  'new_date': '2017-02-09',\n",
       "  'new_time': '18:23:31',\n",
       "  'text': 'What she did was wrong, wrong, wrong. Here is our bi-partisan letter to the White House and OGE. #Donteverdothis  https://t.co/zqeYhcttMB',\n",
       "  'weekday': 4},\n",
       " {'RT': '1081',\n",
       "  'created_at': '2016-11-09 15:43:50',\n",
       "  'fav': '4182',\n",
       "  'hour': '11',\n",
       "  'id': '796377766275018752',\n",
       "  'new_date': '2016-11-09',\n",
       "  'new_time': '11:43:50',\n",
       "  'text': 'President-elect Trump!  Congratulations!',\n",
       "  'weekday': 3}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top 10 fav'd tweets\n",
    "\n",
    "most_favs =  sorted(all_tweets, key=lambda k: int(k['fav']), reverse=True)[0:10]\n",
    "\n",
    "most_favs[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find out what he's tweeting about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get top 100 word freq count\n",
    "\n",
    "all_words = \"\"\n",
    "for twt in all_tweets:\n",
    "    all_words = all_words + \" \" + twt[\"text\"]\n",
    "    \n",
    "words_freq =Counter(all_words.lower().replace(\":\",\"\").split()).most_common()\n",
    "    \n",
    "most_used_words = Counter(all_words.lower().split()).most_common()[0:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get most used hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#benghazi - 38\n",
      "#tbt - 35\n",
      "#utah - 34\n",
      "#utpol - 29\n",
      "#irs - 26\n",
      "#tcot - 20\n",
      "#fastandfurious - 14\n",
      "#ut3rddistrict - 14\n",
      "#irsfail - 11\n",
      "#usa - 9\n",
      "#secretservice - 8\n",
      "#neverforget - 7\n",
      "#breaking - 7\n",
      "#emerycounty - 7\n",
      "#nomidnightmonument - 6\n",
      "#epa - 6\n",
      "#nature - 5\n",
      "#july4 - 5\n",
      "#americanforkcanyon - 4\n",
      "#taxday - 4\n",
      "#oneluckyguy - 4\n",
      "#plannedparenthood - 4\n",
      "#byufootball - 4\n",
      "#gopoversight - 4\n",
      "#natgeo - 4\n",
      "#sxsw - 4\n"
     ]
    }
   ],
   "source": [
    "# get most used hashtags\n",
    "\n",
    "hashtags_freq = []\n",
    "\n",
    "most_used_hashtags = []\n",
    "\n",
    "for word in words_freq:\n",
    "    if word[0][0] == \"#\":\n",
    "        hashtags_freq.append(word)\n",
    "        if word[1] > 3:\n",
    "            most_used_hashtags.append(word)\n",
    "            \n",
    "# fix utah\n",
    "\n",
    "for ind, ht in enumerate(most_used_hashtags):\n",
    "    if ht[0] == \"#utah…\":\n",
    "        add_utah_num = ht[1]\n",
    "        most_used_hashtags.pop(ind)\n",
    "        \n",
    "\n",
    "for ind,ht in enumerate(most_used_hashtags):\n",
    "    if ht[0] == \"#utah\":\n",
    "        most_used_hashtags[ind] = [\"#utah\", ht[1]+add_utah_num]\n",
    "  \n",
    "for ht in most_used_hashtags:\n",
    "    print(ht[0] + \" - \" + str(ht[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get users he tweets @ the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@gopoversight - 505\n",
      "@foxnews - 166\n",
      "@youtube - 51\n",
      "@jasoninthehouse - 49\n",
      "@politico - 41\n",
      "@kslnewsradio - 38\n",
      "@cnn - 37\n",
      "@sltrib - 31\n",
      "@speakerryan - 30\n",
      "@usatoday - 27\n",
      "@wsj - 25\n",
      "@washingtonpost - 24\n",
      "@greta - 23\n",
      "@abc - 22\n",
      "@kslcom - 21\n",
      "@dailycaller - 21\n",
      "@dougwrightshow - 19\n",
      "@tgowdysc - 16\n",
      "@wolfblitzer - 15\n",
      "@speakerboehner - 15\n"
     ]
    }
   ],
   "source": [
    "# get most used ats\n",
    "\n",
    "ats_freq = []\n",
    "\n",
    "most_used_ats = []\n",
    "\n",
    "for word in words_freq:\n",
    "    if word[0][0] == \"@\" and word[0] != \"@\":\n",
    "        ats_freq.append(word)\n",
    "        if word[1] > 14:\n",
    "            most_used_ats.append(word)\n",
    "  \n",
    "for at in most_used_ats:\n",
    "    print(at[0] + \" - \" + str(at[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Twitter data on other members who entered House at same time as Chaffetz ('09)\n",
    "\n",
    "We used this to see if Chaffetz was the most active among his classmates on Twitter. He was.\n",
    "\n",
    "Twitter usernames compiled by [congress-legislators](https://github.com/unitedstates/congress-legislators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished JasonInTheHouse\n",
      "finished RepMikeCoffman\n",
      "finished RepGuthrie\n",
      "finished GreggHarper\n",
      "finished Rep_Hunter\n",
      "finished RepLynnJenkins\n",
      "finished RepLanceNJ7\n",
      "finished RepBlainePress\n",
      "finished RepMcClintock\n",
      "finished RepPeteOlson\n",
      "finished RepErikPaulsen\n",
      "finished CongBillPosey\n",
      "finished DrPhilRoe\n",
      "finished RepRooney\n",
      "finished CongressmanGT\n"
     ]
    }
   ],
   "source": [
    "# scrape twitter vitals for chaffetz' class in House\n",
    "\n",
    "\n",
    "member_uns = [\"JasonInTheHouse\",\n",
    "\"RepMikeCoffman\",\n",
    "\"RepGuthrie\",\n",
    "\"GreggHarper\",\n",
    "\"Rep_Hunter\",\n",
    "\"RepLynnJenkins\",\n",
    "\"RepLanceNJ7\",\n",
    "\"RepBlainePress\",\n",
    "\"RepMcClintock\",\n",
    "\"RepPeteOlson\",\n",
    "\"RepErikPaulsen\",\n",
    "\"CongBillPosey\",\n",
    "\"DrPhilRoe\",\n",
    "\"RepRooney\",\n",
    "\"CongressmanGT\"]\n",
    "\n",
    "class_data = []\n",
    "\n",
    "url_prefix = \"http://www.twitter.com/\"\n",
    "\n",
    "for un in member_uns:\n",
    "    resp = requests.get(url_prefix + un)\n",
    "    html = resp.text\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    vitals = soup.find_all(\"a\", {\"class\":\"ProfileNav-stat\"})\n",
    "    d = {}\n",
    "    for vital in vitals:\n",
    "        d[vital.find_all(\"span\")[0].getText()] = vital.find_all(\"span\")[2].getText()  \n",
    "    d[\"un\"] = un\n",
    "    class_data.append(d)\n",
    "    print(\"finished \" + un)\n",
    "    time.sleep(2) #seconds\n",
    "    \n",
    "longest_vital = [0,0]    \n",
    "\n",
    "for ind, member in enumerate(class_data):\n",
    "    member[\"Tweets\"] = member[\"Tweets\"].replace(\"\\n\",\"\").strip()\n",
    "    if len(member.keys()) > longest_vital[1]:\n",
    "        longest_vital[0] = ind\n",
    "        longest_vital[1] = len(member.keys())\n",
    "    \n",
    "    \n",
    "out_file_name = \"class_09_twitter_vitals.csv\"\n",
    "\n",
    "with open(out_file_name, \"w\") as csvfile:\n",
    "    fieldnames = class_data[longest_vital[0]].keys()\n",
    "    writer = csv.DictWriter(csvfile, fieldnames = fieldnames)\n",
    "    writer.writeheader()\n",
    "    for el in class_data:\n",
    "        writer.writerow(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
